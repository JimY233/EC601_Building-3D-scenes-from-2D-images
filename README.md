# ECBuilding601_-3D-scenes-from-2D-images

Please read EC601_Building_3D_scenes_from_2D_images_Jiaming Yu.pdf. This is the project 1 of EC601 course on topic: Building 3D scenes from 2D images. Another project 1 which is submitted on VQA is under another repository of JimY233.

Reference:

[1] C. B. Choy, D. Xu, J. Gwak, K. Chen, and S. Savarese. 3d-r2n2: A
unified approach for single and multi-view 3d object reconstruction.
In European conference on computer vision, pages 628–644. Springer,
2016.

[2] A. J. Davison, W. W. Mayol, and D. W. Murray. Real-time localization
and mapping with wearable active vision. In The Second IEEE and
ACM International Symposium on Mixed and Augmented Reality, 2003.
Proceedings., pages 18–27. IEEE, 2003.

[3] D. Eigen, C. Puhrsch, and R. Fergus. Depth map prediction from a
single image using a multi-scale deep network. In Advances in neural
information processing systems, pages 2366–2374, 2014.

[4] H. Fan, H. Su, and L. J. Guibas. A point set generation network for
3d object reconstruction from a single image. In Proceedings of the
IEEE conference on computer vision and pattern recognition, pages
605–613, 2017.

[5] B. K. Horn. Shape from shading: A method for obtaining the shape
of a smooth opaque object from one view. 1970.

[6] A. Koutsoudis, F. Arnaoutoglou, and C. Chamzas. On 3d reconstruction
of the old city of xanthi. a minimum budget approach to virtual touring
based on photogrammetry. Journal of Cultural Heritage, 8(1):26–31,
2007.

[7] F. Nex and F. Remondino. Uav for 3d mapping applications: a review.
Applied geomatics, 6(1):1–15, 2014.

[8] M. Roberts, D. Dey, A. Truong, S. Sinha, S. Shah, A. Kapoor,
P. Hanrahan, and N. Joshi. Submodular trajectory optimization for aerial
3d scanning. In Proceedings of the IEEE International Conference on
Computer Vision, pages 5324–5333, 2017.

[9] A. Saxena, M. Sun, and A. Y. Ng. Make3d: Learning 3d scene structure
from a single still image. IEEE transactions on pattern analysis and
machine intelligence, 31(5):824–840, 2008.

[10] M. Tatarchenko, S. R. Richter, R. Ranftl, Z. Li, V. Koltun, and T. Brox.
What do single-view 3d reconstruction networks learn? In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 3405–3414, 2019.

[11] N. Wang, Y. Zhang, Z. Li, Y. Fu, W. Liu, and Y.-G. Jiang. Pixel2mesh:
Generating 3d mesh models from single rgb images. In Proceedings of
the European Conference on Computer Vision (ECCV), pages 52–67,
2018.

[12] J. Wu, C. Zhang, T. Xue, B. Freeman, and J. Tenenbaum. Learning a
probabilistic latent space of object shapes via 3d generative-adversarial
modeling. In Advances in neural information processing systems, pages
82–90, 2016.

[13] Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3d
shapenets: A deep representation for volumetric shapes. In Proceedings
of the IEEE conference on computer vision and pattern recognition,
pages 1912–1920, 2015.

[14] S. Xin, S. Nousias, K. N. Kutulakos, A. C. Sankaranarayanan, S. G.
Narasimhan, and I. Gkioulekas. A theory of fermat paths for non-lineof-sight shape reconstruction. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 6800–6809, 2019.
